!pip install nltk
import nltk
from nltk.tokenize import word_tokenize
from nltk.tag import pos_tag
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
def stochastic_pos_tag(sentence):
  words = word_tokenize(sentence)
  pos_tags = pos_tag(words)
    return pos_tags
example_sentence = "The quick brown fox jumps over the lazy dog."
result_pos_tags = stochastic_pos_tag(example_sentence)
print(f"Original Sentence: {example_sentence}")
print("Stochastic Part-of-Speech Tags:")
for word, pos_tag in result_pos_tags:
    print(f"{word}: {pos_tag}")
